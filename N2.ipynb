{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b489abb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ygments (c:\\users\\prasanna\\anaconda3\\lib\\site-packages)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\prasanna\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\prasanna\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\prasanna\\anaconda3\\lib\\site-packages (from scikit-learn) (1.22.4)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\prasanna\\anaconda3\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\prasanna\\anaconda3\\lib\\site-packages (from scikit-learn) (1.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\users\\prasanna\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\users\\prasanna\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\users\\prasanna\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\users\\prasanna\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\users\\prasanna\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c836d3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\prasanna\\anaconda3\\lib\\site-packages (4.3.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\prasanna\\anaconda3\\lib\\site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\prasanna\\anaconda3\\lib\\site-packages (from gensim) (1.22.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\prasanna\\anaconda3\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\prasanna\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.12.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ygments (c:\\users\\prasanna\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\users\\prasanna\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\users\\prasanna\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\users\\prasanna\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\users\\prasanna\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\users\\prasanna\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03a3cd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bag of Words (Counts):\n",
      "    fascinating  help  is  language  models  natural  processing  requires  \\\n",
      "0            1     0   1         1       0        1           1         0   \n",
      "1            0     0   0         0       0        0           1         1   \n",
      "2            0     1   0         1       1        0           0         0   \n",
      "\n",
      "   techniques  text  understand  us  various  \n",
      "0           0     0           0   0        0  \n",
      "1           1     1           0   0        1  \n",
      "2           0     1           1   1        0  \n",
      "\n",
      "Bag of Words (Normalized):\n",
      "    fascinating   help   is  language  models  natural  processing  requires  \\\n",
      "0          0.2  0.000  0.2     0.200   0.000      0.2         0.2       0.0   \n",
      "1          0.0  0.000  0.0     0.000   0.000      0.0         0.2       0.2   \n",
      "2          0.0  0.167  0.0     0.167   0.167      0.0         0.0       0.0   \n",
      "\n",
      "   techniques   text  understand     us  various  \n",
      "0         0.0  0.000       0.000  0.000      0.0  \n",
      "1         0.2  0.200       0.000  0.000      0.2  \n",
      "2         0.0  0.167       0.167  0.167      0.0  \n",
      "\n",
      "TF-IDF:\n",
      "    fascinating  help    is  language  models  natural  processing  requires  \\\n",
      "0         0.49  0.00  0.49     0.373    0.00     0.49       0.373      0.00   \n",
      "1         0.00  0.00  0.00     0.000    0.00     0.00       0.373      0.49   \n",
      "2         0.00  0.44  0.00     0.335    0.44     0.00       0.000      0.00   \n",
      "\n",
      "   techniques   text  understand    us  various  \n",
      "0        0.00  0.000        0.00  0.00     0.00  \n",
      "1        0.49  0.373        0.00  0.00     0.49  \n",
      "2        0.00  0.335        0.44  0.44     0.00  \n",
      "\n",
      "Word2Vec Embeddings (sample):\n",
      "text: [-0.0107  0.0047  0.1021  0.1802 -0.1861]\n",
      "processing: [-0.1423  0.1292  0.1795 -0.1003 -0.0753]\n",
      "language: [ 0.1476 -0.0307 -0.0907  0.1311 -0.0972]\n",
      "understand: [-0.0363  0.0575  0.0198 -0.1657 -0.189 ]\n",
      "us: [0.1462 0.1014 0.1352 0.0153 0.127 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "corpus = [\n",
    "    \"Natural language processing is fascinating\",\n",
    "    \"Processing text requires various techniques\",\n",
    "    \"Language models help us understand text\"\n",
    "]\n",
    "\n",
    "# Bag of Words (Count + Normalized)\n",
    "cv = CountVectorizer()\n",
    "bow = cv.fit_transform(corpus).toarray()\n",
    "words = cv.get_feature_names()\n",
    "print(\"\\nBag of Words (Counts):\\n\", pd.DataFrame(bow, columns=words))\n",
    "print(\"\\nBag of Words (Normalized):\\n\", pd.DataFrame(np.round(bow / bow.sum(axis=1, keepdims=True), 3), columns=words))\n",
    "\n",
    "# TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(corpus).toarray()\n",
    "print(\"\\nTF-IDF:\\n\", pd.DataFrame(np.round(tfidf_matrix, 3), columns=tfidf.get_feature_names()))\n",
    "\n",
    "# Word2Vec (5 sample words)\n",
    "tokens = [s.lower().split() for s in corpus]\n",
    "w2v = Word2Vec(tokens, vector_size=5, window=2, min_count=1, workers=1)\n",
    "print(\"\\nWord2Vec Embeddings (sample):\")\n",
    "for word in list(w2v.wv.key_to_index)[:5]:\n",
    "    print(f\"{word}: {np.round(w2v.wv[word], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7da409",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
